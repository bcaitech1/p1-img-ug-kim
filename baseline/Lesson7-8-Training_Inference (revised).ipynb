{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"colab":{"name":"Lesson7-8-Training&Inference (revised).ipynb","provenance":[{"file_id":"1VSG9MObiVZHW1YfiE87H9c71pYgyem_l","timestamp":1617686725300}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"applied-artist"},"source":["# Lesson 7 & 8 - Training & Inference\n","- 7강과 8강에서는 모델을 학습하고 추론하는 방법에 대해 알아보았습니다.\n","- 이번 실습 자료에서는 다양한 Loss, Optimizer, Scheduler를 활용하는 방법을 알아봅니다.\n","- 또한, Checkpoint, Early Stopping과 같은 학습을 도와주는 Callback 방법을 알아봅니다.\n","- 그리고 Graident Accumulation 방법을 활용하여 학습을 진행해봅니다.\n","## 0. Libraries & Configurations\n","- 시각화에 필요한 라이브러리와 학습에 필요한 설정을 합니다."],"id":"applied-artist"},{"cell_type":"code","metadata":{"id":"available-fiber"},"source":["# !pip install -U ipywidgets > /dev/null"],"id":"available-fiber","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"twenty-facial"},"source":["import random\n","import os, sys\n","from importlib import import_module\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Subset\n","from torch.optim import SGD, Adam, AdamW\n","from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n","\n","sys.path.append(os.path.abspath('..'))\n","from dataset import MaskBaseDataset\n","from model import *\n","\n","def seed_everything(seed):\n","    \"\"\"\n","    동일한 조건으로 학습을 할 때, 동일한 결과를 얻기 위해 seed를 고정시킵니다.\n","    \n","    Args:\n","        seed: seed 정수값\n","    \"\"\"\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    np.random.seed(seed)\n","    random.seed(seed)\n","seed_everything(42)"],"id":"twenty-facial","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"described-cursor"},"source":["# -- parameters\n","img_root = '/opt/ml/input/data/train/images'  # 학습 이미지 폴더의 경로\n","label_path = '/opt/ml/input/data/train/train.csv'  # 학습 메타파일의 경로\n","\n","model_name = \"VGG19\"  # 모델 이름\n","use_pretrained = True  # pretrained-model의 사용 여부\n","freeze_backbone = False  # classifier head 이 외 부분을 업데이트되지 않게 할 것인지 여부\n","\n","val_split = 0.4  # validation dataset의 비율\n","batch_size = 2\n","num_workers = 0\n","num_classes = 18\n","\n","num_epochs = 5  # 학습할 epoch의 수\n","lr = 1e-4\n","lr_decay_step = 10\n","\n","train_log_interval = 20  # logging할 iteration의 주기\n","name = \"02_vgg\"  # 결과를 저장하는 폴더의 이름\n","\n","# -- settings\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")"],"id":"described-cursor","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"alternative-triangle"},"source":["## 1. Loss\n","- Image Classification에 사용되는 다양한 loss 함수들이 존재합니다. 각 loss 함수는 목적이 있고 풀고자 하는 문제에 맞게 적용을 해야합니다.\n","- Cross Entropy Loss는 두 분포간의 불확실성을 최소화 하는 목적을 가진 분류에 사용되는 일반적인 손실함수입니다.\n","- Focal Loss는 Imbalanced Data 문제를 해결하기 위한 손실함수입니다. [참고](https://arxiv.org/pdf/1708.02002.pdf)\n","- Label Smoothing은 학습 데이터의 representation을 더 잘나타내는데 도움을 줍니다. [참고](https://arxiv.org/pdf/1906.02629.pdf)\n","- F1 Loss는 F1 score 향상을 목적으로 하는 손실함수입니다."],"id":"alternative-triangle"},{"cell_type":"code","metadata":{"tags":[],"id":"framed-radical"},"source":["# -- Cross Entropy Loss\n","class CrossEntropyLoss(nn.Module):\n","    def __init__(self, weight=None, reduction='mean'):\n","        nn.Module.__init__(self)\n","        self.weight = weight\n","        self.reduction = reduction\n","\n","    def forward(self, input_tensor, target_tensor):\n","        log_prob = F.log_softmax(input_tensor, dim=-1)\n","        prob = torch.exp(log_prob)\n","        return F.nll_loss(\n","            log_prob,\n","            target_tensor,\n","            weight=self.weight,\n","            reduction=self.reduction\n","        )"],"id":"framed-radical","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"id":"muslim-juice"},"source":["# -- Focal Loss\n","# https://discuss.pytorch.org/t/is-this-a-correct-implementation-for-focal-loss-in-pytorch/43327/8\n","class FocalLoss(nn.Module):\n","    def __init__(self, weight=None,\n","                 gamma=2., reduction='mean'):\n","        nn.Module.__init__(self)\n","        self.weight = weight\n","        self.gamma = gamma\n","        self.reduction = reduction\n","\n","    def forward(self, input_tensor, target_tensor):\n","        log_prob = F.log_softmax(input_tensor, dim=-1)\n","        prob = torch.exp(log_prob)\n","        return F.nll_loss(\n","            ((1 - prob) ** self.gamma) * log_prob,\n","            target_tensor,\n","            weight=self.weight,\n","            reduction=self.reduction\n","        )"],"id":"muslim-juice","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"id":"egyptian-protest"},"source":["# -- Label Smoothing Loss\n","class LabelSmoothingLoss(nn.Module):\n","    def __init__(self, classes=3, smoothing=0.0, dim=-1):\n","        super(LabelSmoothingLoss, self).__init__()\n","        self.confidence = 1.0 - smoothing\n","        self.smoothing = smoothing\n","        self.cls = classes\n","        self.dim = dim\n","\n","    def forward(self, pred, target):\n","        pred = pred.log_softmax(dim=self.dim)\n","        with torch.no_grad():\n","            true_dist = torch.zeros_like(pred)\n","            true_dist.fill_(self.smoothing / (self.cls - 1))\n","            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n","        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"],"id":"egyptian-protest","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"id":"reflected-permission"},"source":["# -- F1 Loss\n","# https://gist.github.com/SuperShinyEyes/dcc68a08ff8b615442e3bc6a9b55a354\n","class F1Loss(nn.Module):\n","    def __init__(self, classes=3, epsilon=1e-7):\n","        super().__init__()\n","        self.classes = classes\n","        self.epsilon = epsilon\n","    def forward(self, y_pred, y_true):\n","        assert y_pred.ndim == 2\n","        assert y_true.ndim == 1\n","        y_true = F.one_hot(y_true, self.classes).to(torch.float32)\n","        y_pred = F.softmax(y_pred, dim=1)\n","\n","        tp = (y_true * y_pred).sum(dim=0).to(torch.float32)\n","        tn = ((1 - y_true) * (1 - y_pred)).sum(dim=0).to(torch.float32)\n","        fp = ((1 - y_true) * y_pred).sum(dim=0).to(torch.float32)\n","        fn = (y_true * (1 - y_pred)).sum(dim=0).to(torch.float32)\n","\n","        precision = tp / (tp + fp + self.epsilon)\n","        recall = tp / (tp + fn + self.epsilon)\n","\n","        f1 = 2 * (precision * recall) / (precision + recall + self.epsilon)\n","        f1 = f1.clamp(min=self.epsilon, max=1 - self.epsilon)\n","        return 1 - f1.mean()"],"id":"reflected-permission","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"id":"prime-austin"},"source":["criterion = CrossEntropyLoss()"],"id":"prime-austin","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"suspended-electronics"},"source":["## 2. Optimizer\n","- 파이토치는 코드를 간단히 수정하여 다양한 optimizer를 사용할 수 있습니다.\n","- 또한 Model의 레이어마다 다른 learning rate를 적용할 수도 있습니다."],"id":"suspended-electronics"},{"cell_type":"code","metadata":{"id":"coated-warrant"},"source":["# -- model\n","model_cls = getattr(import_module(\"model\"), model_name)\n","model = model_cls(\n","    num_classes=num_classes,\n","    pretrained=use_pretrained,\n","    freeze=freeze_backbone\n",").to(device)"],"id":"coated-warrant","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"established-anthony"},"source":["# -- SGD optimizer\n","optimizer = SGD(model.parameters(), lr=lr, weight_decay=5e-4)"],"id":"established-anthony","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"unexpected-porter"},"source":["# -- Adam optimizer\n","optimizer = Adam(model.parameters(), lr=lr, weight_decay=5e-4)"],"id":"unexpected-porter","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cellular-background"},"source":["- 한 모델에 다른 learning rate를 적용시키기 위해 모델의 구조를 살펴봅시다."],"id":"cellular-background"},{"cell_type":"code","metadata":{"tags":[],"id":"atmospheric-sleep","outputId":"add908e1-4cff-4a9a-d20a-0f8c3dc6c755"},"source":["list(model.named_children())"],"id":"atmospheric-sleep","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('net',\n","  VGG(\n","    (features): Sequential(\n","      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU(inplace=True)\n","      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","      (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (9): ReLU(inplace=True)\n","      (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (12): ReLU(inplace=True)\n","      (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","      (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (16): ReLU(inplace=True)\n","      (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (19): ReLU(inplace=True)\n","      (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (22): ReLU(inplace=True)\n","      (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (25): ReLU(inplace=True)\n","      (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","      (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (29): ReLU(inplace=True)\n","      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (32): ReLU(inplace=True)\n","      (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (35): ReLU(inplace=True)\n","      (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (38): ReLU(inplace=True)\n","      (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","      (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (42): ReLU(inplace=True)\n","      (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (45): ReLU(inplace=True)\n","      (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (48): ReLU(inplace=True)\n","      (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (51): ReLU(inplace=True)\n","      (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    )\n","    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","    (classifier): Sequential(\n","      (0): Linear(in_features=25088, out_features=4096, bias=True)\n","      (1): ReLU(inplace=True)\n","      (2): Dropout(p=0.5, inplace=False)\n","      (3): Linear(in_features=4096, out_features=4096, bias=True)\n","      (4): ReLU(inplace=True)\n","      (5): Dropout(p=0.5, inplace=False)\n","      (6): Linear(in_features=4096, out_features=18, bias=True)\n","    )\n","  ))]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"worse-virtue"},"source":["# -- optimizer: Different Learning Rates on different layers\n","\n","# features 레이어와 classifier 레이어에서 서로 다른 learning rate를 적용하여 optimizer를 정의할 수 있습니다.\n","train_params = [{'params': getattr(model.net, 'features').parameters(), 'lr': lr / 10, 'weight_decay':5e-4},\n","                {'params': getattr(model.net, 'classifier').parameters(), 'lr': lr, 'weight_decay':5e-4}]\n","optimizer = Adam(train_params)"],"id":"worse-virtue","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tracked-nitrogen"},"source":["## 3. Scheduler\n","- Scheduler은 optimizer의 learning rate를 동적으로 변경시키는 기능을 합니다.\n","- Optimizer과 Scheduler를 적절히 활용하면 모델이 좋은 성능으로 Fitting하는데 도움을 줍니다."],"id":"tracked-nitrogen"},{"cell_type":"code","metadata":{"id":"balanced-precipitation"},"source":["# -- scheduler: StepLR\n","# 지정된 step마다 learning rate를 감소시킵니다.\n","scheduler = StepLR(optimizer, lr_decay_step, gamma=0.5)"],"id":"balanced-precipitation","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"israeli-privacy"},"source":["# -- scheduler: ReduceLROnPlateau\n","# 성능이 향상되지 않을 때 learning rate를 줄입니다. patience=10은 10회 동안 성능 향상이 없을 경우입니다.\n","scheduler = ReduceLROnPlateau(optimizer, factor=0.1, patience=10)"],"id":"israeli-privacy","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"italian-bargain"},"source":["# -- scheduler: CosineAnnealingLR\n","# CosineAnnealing은 learning rate를 cosine 그래프처럼 변화시킵니다.\n","scheduler = CosineAnnealingLR(optimizer, T_max=2, eta_min=0.)"],"id":"italian-bargain","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"statutory-onion"},"source":["## 4. Metric\n","- Classification 성능을 표현할 때 다양한 평가지표가 있습니다.\n","- Accuracy: 모델이 정확하게 예측한 객체의 비율\n","- True Positive(TP): 실제 True인 정답을 True라고 예측 (정답)\n","- False Positive(FP): 실제 False인 정답을 True라고 예측 (오답)\n","- False Negative(FN): 실제 True인 정답을 False라고 예측 (오답)\n","- True Negative(TN): 실제 False인 정답을 False라고 예측 (정답)\n","- Precision(정밀도): TP / (TP + FP)\n","- Recall(재현율): TP / (TP + FN)"],"id":"statutory-onion"},{"cell_type":"code","metadata":{"id":"mature-princeton"},"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","y_true = [0, 1, 2, 0, 1, 2]\n","y_pred = [0, 2, 1, 0, 0, 1]"],"id":"mature-princeton","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"narrow-producer","outputId":"069d7f1f-08f9-47ab-edef-a172c8296350"},"source":["# -- Accuracy\n","accuracy_score(y_true, y_pred)"],"id":"narrow-producer","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.3333333333333333"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"lonely-greensboro","outputId":"6a804157-5fbd-4a05-94c9-9026e45facb3"},"source":["# -- Accuracy\n","# Normalize를 안하면 맞춘 개수가 표시된다\n","accuracy_score(y_true, y_pred, normalize=False)"],"id":"lonely-greensboro","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"parallel-passage","outputId":"2ab2c566-3acd-4dfd-846e-44d579e44d48"},"source":["# -- Precision\n","precision = precision_score(y_true, y_pred, average='macro')\n","precision"],"id":"parallel-passage","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.2222222222222222"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"sized-accuracy","outputId":"56183f53-3d65-476d-a41e-dd9ce1b9ed06"},"source":["# -- Recall\n","recall = recall_score(y_true, y_pred, average='macro')\n","recall"],"id":"sized-accuracy","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.3333333333333333"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"union-nomination","outputId":"ce2163db-13e8-4c4e-add1-3d37e950c146"},"source":["# -- f1 score\n","2 * (precision * recall) / (precision + recall)"],"id":"union-nomination","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.26666666666666666"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"tested-friday","outputId":"93494ea4-009b-4a2a-a898-a4e401cdbc00"},"source":["# -- f1 score (sklearn)\n","f1_score(y_true, y_pred, average='macro')"],"id":"tested-friday","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.26666666666666666"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"educated-scientist"},"source":["## 5. Training process"],"id":"educated-scientist"},{"cell_type":"code","metadata":{"id":"coordinated-essex"},"source":["# -- dataset\n","dataset_module = getattr(import_module(\"dataset\"), 'MaskBaseDataset')\n","dataset = dataset_module(\n","    data_dir=img_root,\n",")\n","num_classes = dataset.num_classes  # 18\n","\n","# -- augmentation\n","transform_module = getattr(import_module(\"dataset\"), 'BaseAugmentation')\n","transform = transform_module(\n","    resize=[128, 96],\n","    mean=dataset.mean,\n","    std=dataset.std,\n",")\n","dataset.set_transform(transform)\n","\n","\n","# -- data_loader\n","train_set, val_set = dataset.split_dataset()\n","\n","train_loader = torch.utils.data.DataLoader(\n","    train_set,\n","    batch_size=batch_size,\n","    num_workers=num_workers,\n","    shuffle=True\n",")\n","\n","val_loader = torch.utils.data.DataLoader(\n","    val_set,\n","    batch_size=batch_size,\n","    num_workers=num_workers,\n","    shuffle=False\n",")"],"id":"coordinated-essex","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"senior-massachusetts"},"source":["### 5.1 Callback - Checkpoint, Early Stopping"],"id":"senior-massachusetts"},{"cell_type":"code","metadata":{"id":"alleged-session"},"source":["# -- Callback1: Checkpoint - Accuracy가 높아질 때마다 모델을 저장합니다.\n","# 학습 코드에서 이어집니다.\n","\n","# -- Callback2: Early Stopping - 성능이 일정 기간동안 향상이 없을 경우 학습을 종료합니다.\n","patience = 10\n","counter = 0\n","# 학습 코드에서 이어집니다."],"id":"alleged-session","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"external-celtic"},"source":["### 5.2 Training Method - Gradient Accumulation\n","- Graident Accumulation은 한 iteration에 파라미터를 업데이트시키는게 아니라, gradient를 여러 iteration 동안 쌓아서 업데이트시킵니다. 한 번에 파라미터를 업데이트시키는 건 noise가 있을 수 있으므로, 여러번 쌓아서 한번에 업데이트 시킴으로써 그러한 문제를 방지하기 위함입니다."],"id":"external-celtic"},{"cell_type":"code","metadata":{"id":"leading-sympathy"},"source":["# -- Gradient Accumulation\n","accumulation_steps = 2\n","# 학습코드에서 이어집니다."],"id":"leading-sympathy","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"narrow-initial"},"source":["### 5.3 Training Loop"],"id":"narrow-initial"},{"cell_type":"code","metadata":{"id":"parliamentary-occasion","outputId":"2e7aa0c3-a83a-4b02-f2bc-52d2bee79199"},"source":["os.makedirs(os.path.join(os.getcwd(), 'results', name), exist_ok=True)\n","\n","counter = 0\n","best_val_acc = 0\n","best_val_loss = np.inf\n","for epoch in range(num_epochs):\n","    # train loop\n","    model.train()\n","    loss_value = 0\n","    matches = 0\n","    for idx, train_batch in enumerate(train_loader):\n","        inputs, labels = train_batch\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        outs = model(inputs)\n","        preds = torch.argmax(outs, dim=-1)\n","        loss = criterion(outs, labels)\n","\n","        loss.backward()\n","        \n","        # -- Gradient Accumulation\n","        if (idx+1) % accumulation_steps == 0:\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","        loss_value += loss.item()\n","        matches += (preds == labels).sum().item()\n","        if (idx + 1) % train_log_interval == 0:\n","            train_loss = loss_value / train_log_interval\n","            train_acc = matches / batch_size / train_log_interval\n","            current_lr = scheduler.get_last_lr()\n","            print(\n","                f\"Epoch[{epoch}/{num_epochs}]({idx + 1}/{len(train_loader)}) || \"\n","                f\"training loss {train_loss:4.4} || training accuracy {train_acc:4.2%} || lr {current_lr}\"\n","            )\n","\n","            loss_value = 0\n","            matches = 0\n","\n","    scheduler.step()\n","\n","    # val loop\n","    with torch.no_grad():\n","        print(\"Calculating validation results...\")\n","        model.eval()\n","        val_loss_items = []\n","        val_acc_items = []\n","        for val_batch in val_loader:\n","            inputs, labels = val_batch\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            outs = model(inputs)\n","            preds = torch.argmax(outs, dim=-1)\n","\n","            loss_item = criterion(outs, labels).item()\n","            acc_item = (labels == preds).sum().item()\n","            val_loss_items.append(loss_item)\n","            val_acc_items.append(acc_item)\n","\n","        val_loss = np.sum(val_loss_items) / len(val_loader)\n","        val_acc = np.sum(val_acc_items) / len(val_set)\n","        \n","        # Callback1: validation accuracy가 향상될수록 모델을 저장합니다.\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","        if val_acc > best_val_acc:\n","            print(\"New best model for val accuracy! saving the model..\")\n","            torch.save(model.state_dict(), f\"results/{name}/{epoch:03}_accuracy_{val_acc:4.2%}.ckpt\")\n","            best_val_acc = val_acc\n","            counter = 0\n","        else:\n","            counter += 1\n","        # Callback2: patience 횟수 동안 성능 향상이 없을 경우 학습을 종료시킵니다.\n","        if counter > patience:\n","            print(\"Early Stopping...\")\n","            break\n","        \n","        \n","        print(\n","            f\"[Val] acc : {val_acc:4.2%}, loss: {val_loss:4.2} || \"\n","            f\"best acc : {best_val_acc:4.2%}, best loss: {best_val_loss:4.2}\"\n","        )"],"id":"parliamentary-occasion","execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch[0/5](20/7560) || training loss 2.624 || training accuracy 22.50% || lr [1e-05, 0.0001]\n","Epoch[0/5](40/7560) || training loss 2.934 || training accuracy 22.50% || lr [1e-05, 0.0001]\n","Epoch[0/5](60/7560) || training loss 2.686 || training accuracy 25.00% || lr [1e-05, 0.0001]\n","Epoch[0/5](80/7560) || training loss 2.786 || training accuracy 27.50% || lr [1e-05, 0.0001]\n","Epoch[0/5](100/7560) || training loss 2.568 || training accuracy 22.50% || lr [1e-05, 0.0001]\n","Epoch[0/5](120/7560) || training loss 2.22 || training accuracy 20.00% || lr [1e-05, 0.0001]\n","Epoch[0/5](140/7560) || training loss 2.383 || training accuracy 32.50% || lr [1e-05, 0.0001]\n","Epoch[0/5](160/7560) || training loss 2.224 || training accuracy 25.00% || lr [1e-05, 0.0001]\n","Epoch[0/5](180/7560) || training loss 2.314 || training accuracy 32.50% || lr [1e-05, 0.0001]\n","Epoch[0/5](200/7560) || training loss 2.521 || training accuracy 22.50% || lr [1e-05, 0.0001]\n","Epoch[0/5](220/7560) || training loss 2.705 || training accuracy 20.00% || lr [1e-05, 0.0001]\n","Epoch[0/5](240/7560) || training loss 2.402 || training accuracy 25.00% || lr [1e-05, 0.0001]\n","Epoch[0/5](260/7560) || training loss 1.759 || training accuracy 40.00% || lr [1e-05, 0.0001]\n","Epoch[0/5](280/7560) || training loss 1.948 || training accuracy 45.00% || lr [1e-05, 0.0001]\n","Epoch[0/5](300/7560) || training loss 2.146 || training accuracy 35.00% || lr [1e-05, 0.0001]\n","Epoch[0/5](320/7560) || training loss 1.836 || training accuracy 45.00% || lr [1e-05, 0.0001]\n","Epoch[0/5](340/7560) || training loss 1.977 || training accuracy 40.00% || lr [1e-05, 0.0001]\n","Epoch[0/5](360/7560) || training loss 1.759 || training accuracy 47.50% || lr [1e-05, 0.0001]\n","Epoch[0/5](380/7560) || training loss 1.429 || training accuracy 60.00% || lr [1e-05, 0.0001]\n","Epoch[0/5](400/7560) || training loss 1.672 || training accuracy 55.00% || lr [1e-05, 0.0001]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dated-turner"},"source":[""],"id":"dated-turner","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"experienced-clock"},"source":["## 6. Reference\n","- [sumni blog post](https://sumniya.tistory.com/26)"],"id":"experienced-clock"},{"cell_type":"code","metadata":{"id":"aquatic-crawford"},"source":[""],"id":"aquatic-crawford","execution_count":null,"outputs":[]}]}