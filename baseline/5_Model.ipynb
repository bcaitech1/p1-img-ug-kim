{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "Lesson5-Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "knowing-healthcare"
      },
      "source": [
        "from pprint import pprint\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "id": "knowing-healthcare",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "promising-kidney"
      },
      "source": [
        "## Lesson 5 - Model\n",
        " - 이번 실습 자료에서는 강의시간에 다루었던 파이토치 모델을 정의하는 방법에 대해 실습하겠습니다.\n",
        " - 파이토치 모델은 기본적으로 `nn.Module` 클래스를 상속하여 사용합니다.\n",
        "     - [공식문서](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)에 따르면 `nn.Module` 은 다음과 같은 기능을 합니다\n",
        "     ```\n",
        "     Base class for all neural network modules.\n",
        "     Your models should also subclass this class.\n",
        "     Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes:\n",
        "     ```"
      ],
      "id": "promising-kidney"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "absolute-regulation"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3, bias=True)\n",
        "        self.bn1 = nn.BatchNorm2d(num_features=3)\n",
        "        self.conv2 = nn.Conv2d(in_channels=3, out_channels=5, kernel_size=3, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        return F.relu(self.conv2(x))"
      ],
      "id": "absolute-regulation",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "detailed-dylan",
        "outputId": "55516a5d-4cb3-4df2-9f52-5ed207a3c04b"
      },
      "source": [
        "model = Model()\n",
        "model"
      ],
      "id": "detailed-dylan",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (conv1): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sustained-mineral"
      },
      "source": [
        "### 모델 디버깅\n",
        " - 파이토치 모델들은 다음과 같은 방법들을 통해 파라미터를 눈으로 확인할 수 있습니다."
      ],
      "id": "sustained-mineral"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "spoken-frank",
        "outputId": "501fe5f3-e059-4046-bf72-8006e6ed1041"
      },
      "source": [
        "# 1. using named_parameters()\n",
        "for param, weight in model.named_parameters():\n",
        "    print(f\"{param:20} - size: {weight.size()}\")\n",
        "    print(weight)\n",
        "    print(\"-\" * 100)\n",
        "    print()"
      ],
      "id": "spoken-frank",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1.weight         - size: torch.Size([3, 1, 3, 3])\n",
            "Parameter containing:\n",
            "tensor([[[[ 0.2264,  0.2768, -0.2716],\n",
            "          [-0.3121,  0.3171, -0.2744],\n",
            "          [-0.2630,  0.2822,  0.1777]]],\n",
            "\n",
            "\n",
            "        [[[-0.2105, -0.0697,  0.0058],\n",
            "          [-0.0030, -0.0819,  0.2346],\n",
            "          [ 0.2764, -0.2938, -0.1024]]],\n",
            "\n",
            "\n",
            "        [[[-0.2025,  0.1796,  0.2938],\n",
            "          [ 0.3048, -0.2732,  0.2842],\n",
            "          [-0.3299,  0.0659, -0.0495]]]], requires_grad=True)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "conv1.bias           - size: torch.Size([3])\n",
            "Parameter containing:\n",
            "tensor([-0.1888, -0.1223, -0.1941], requires_grad=True)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "bn1.weight           - size: torch.Size([3])\n",
            "Parameter containing:\n",
            "tensor([1., 1., 1.], requires_grad=True)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "bn1.bias             - size: torch.Size([3])\n",
            "Parameter containing:\n",
            "tensor([0., 0., 0.], requires_grad=True)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "conv2.weight         - size: torch.Size([5, 3, 3, 3])\n",
            "Parameter containing:\n",
            "tensor([[[[-0.1148,  0.1610,  0.1144],\n",
            "          [-0.1461,  0.1109,  0.0340],\n",
            "          [ 0.1891, -0.1424, -0.1381]],\n",
            "\n",
            "         [[-0.1193, -0.1736, -0.0267],\n",
            "          [-0.0312, -0.0223, -0.0892],\n",
            "          [-0.1073,  0.0360, -0.0434]],\n",
            "\n",
            "         [[-0.1348, -0.1387,  0.1024],\n",
            "          [ 0.0397, -0.0577, -0.1530],\n",
            "          [-0.1001,  0.1715, -0.0153]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1722,  0.0517, -0.0629],\n",
            "          [ 0.1682,  0.0565,  0.1647],\n",
            "          [-0.0230, -0.1156, -0.1542]],\n",
            "\n",
            "         [[ 0.0370, -0.1518, -0.0013],\n",
            "          [-0.0431,  0.0341, -0.0335],\n",
            "          [-0.1219,  0.0302,  0.1259]],\n",
            "\n",
            "         [[-0.1327,  0.1287,  0.0202],\n",
            "          [-0.1142, -0.1443,  0.0142],\n",
            "          [-0.1572, -0.1501,  0.1459]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0721, -0.0297, -0.0048],\n",
            "          [-0.1838,  0.1055,  0.0106],\n",
            "          [ 0.1605, -0.0249,  0.1466]],\n",
            "\n",
            "         [[-0.0058,  0.0688, -0.1684],\n",
            "          [-0.0244, -0.0042,  0.1471],\n",
            "          [ 0.1722, -0.1729, -0.0693]],\n",
            "\n",
            "         [[-0.1367,  0.0289, -0.1668],\n",
            "          [-0.0907, -0.1705,  0.0901],\n",
            "          [-0.0084, -0.1194,  0.1117]]],\n",
            "\n",
            "\n",
            "        [[[-0.0076,  0.0846, -0.1553],\n",
            "          [ 0.1665,  0.1292,  0.0738],\n",
            "          [ 0.0451,  0.0048,  0.0185]],\n",
            "\n",
            "         [[-0.1773,  0.1831, -0.0103],\n",
            "          [ 0.1169,  0.1641, -0.0804],\n",
            "          [-0.0501, -0.0212, -0.1302]],\n",
            "\n",
            "         [[ 0.1438, -0.0782,  0.1319],\n",
            "          [-0.0802, -0.0071,  0.0556],\n",
            "          [-0.1689, -0.0469, -0.0840]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0562, -0.0257, -0.0258],\n",
            "          [ 0.1155,  0.0083, -0.1232],\n",
            "          [-0.0255,  0.1090, -0.1705]],\n",
            "\n",
            "         [[ 0.1277, -0.0081, -0.1876],\n",
            "          [ 0.1439,  0.1627, -0.0208],\n",
            "          [-0.0896, -0.1187,  0.1468]],\n",
            "\n",
            "         [[ 0.0756, -0.0290,  0.0264],\n",
            "          [-0.1586,  0.0454,  0.0562],\n",
            "          [-0.0328, -0.1194, -0.0551]]]], requires_grad=True)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "turkish-wisdom",
        "outputId": "df56fa11-2419-4f71-a234-e881f4d3e33a"
      },
      "source": [
        "# 2. directly access with member variable\n",
        "print(model.conv1.weight)\n",
        "print(model.conv1.bias)"
      ],
      "id": "turkish-wisdom",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[[[ 0.2264,  0.2768, -0.2716],\n",
            "          [-0.3121,  0.3171, -0.2744],\n",
            "          [-0.2630,  0.2822,  0.1777]]],\n",
            "\n",
            "\n",
            "        [[[-0.2105, -0.0697,  0.0058],\n",
            "          [-0.0030, -0.0819,  0.2346],\n",
            "          [ 0.2764, -0.2938, -0.1024]]],\n",
            "\n",
            "\n",
            "        [[[-0.2025,  0.1796,  0.2938],\n",
            "          [ 0.3048, -0.2732,  0.2842],\n",
            "          [-0.3299,  0.0659, -0.0495]]]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.1888, -0.1223, -0.1941], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stunning-patient"
      },
      "source": [
        ""
      ],
      "id": "stunning-patient",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "impressive-smile"
      },
      "source": [
        "### 학습된 모델 저장하기\n",
        " - `torch.save(model.state_dict(), save_path)`"
      ],
      "id": "impressive-smile"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "august-austin",
        "outputId": "1f6c1eb9-edea-4ee1-f581-205de73248f5"
      },
      "source": [
        "import os\n",
        "\n",
        "save_folder = \"./runs/\"\n",
        "save_path = os.path.join(save_folder, \"best.pth\")   # ./runs/best.pth\n",
        "os.makedirs(save_folder, exist_ok=True)  \n",
        "\n",
        "torch.save(model.state_dict(), save_path)\n",
        "print(f\"Model saving success at {save_path}\")\n",
        "print(f\"Saved models : {os.listdir(save_folder)}\")"
      ],
      "id": "august-austin",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model saving success at ./runs/best.pth\n",
            "Saved models : ['best.pth']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "academic-toolbox"
      },
      "source": [
        "### 저장된 모델 불러오기\n",
        " - model.load_state_dict(torch.load(save_path))"
      ],
      "id": "academic-toolbox"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "impressed-vocabulary",
        "outputId": "f3b88199-3a52-4f4b-d894-72a01b6bf597"
      },
      "source": [
        "new_model = Model()\n",
        "new_model.load_state_dict(torch.load(save_path))\n",
        "print(f\"Model loading success from {save_path}\")"
      ],
      "id": "impressed-vocabulary",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model loading success from ./runs/best.pth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "optional-cylinder"
      },
      "source": [
        "#### 저장된 모델이 잘 불러와졌는지 확인해봅시다"
      ],
      "id": "optional-cylinder"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "promising-jesus",
        "outputId": "e46d85a1-af5f-4e40-b84e-918b367b6990"
      },
      "source": [
        "for (name, trained_weight), (_, saved_weight) in zip(model.named_parameters(), new_model.named_parameters()):\n",
        "    is_equal = torch.equal(trained_weight, saved_weight)\n",
        "    print(f\"parameter {name:15} from trained model and loaded model is equal? -> {is_equal}\")"
      ],
      "id": "promising-jesus",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "parameter conv1.weight    from trained model and loaded model is equal? -> True\n",
            "parameter conv1.bias      from trained model and loaded model is equal? -> True\n",
            "parameter bn1.weight      from trained model and loaded model is equal? -> True\n",
            "parameter bn1.bias        from trained model and loaded model is equal? -> True\n",
            "parameter conv2.weight    from trained model and loaded model is equal? -> True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aging-headline"
      },
      "source": [
        "#### state_dict() 이 무엇인가요?\n",
        " - 모델의 저장과 로딩에 `state_dict()` 을 사용하는데, 기능이 무엇인가요?\n",
        " - 기본적으로 위에서 살펴본 `.named_parameters()` 와 매우 유사합니다\n",
        " - model parameter 를 Key 로 가지고, model weights 를 Value 로 가지는 파이썬 딕셔너리일 뿐입니다. \n",
        "   (정확한 Type 은 파이썬 내장 라이브러리 collections.OrderDict 입니다)"
      ],
      "id": "aging-headline"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "social-stamp",
        "outputId": "01683ef9-168e-4bc3-d397-a325b5c95e17"
      },
      "source": [
        "for param, weight in model.state_dict().items():\n",
        "    print(f\"{param:20} - size: {weight.size()}\")\n",
        "    print(weight)\n",
        "    print(\"-\" * 100)"
      ],
      "id": "social-stamp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1.weight         - size: torch.Size([3, 1, 3, 3])\n",
            "tensor([[[[ 0.2264,  0.2768, -0.2716],\n",
            "          [-0.3121,  0.3171, -0.2744],\n",
            "          [-0.2630,  0.2822,  0.1777]]],\n",
            "\n",
            "\n",
            "        [[[-0.2105, -0.0697,  0.0058],\n",
            "          [-0.0030, -0.0819,  0.2346],\n",
            "          [ 0.2764, -0.2938, -0.1024]]],\n",
            "\n",
            "\n",
            "        [[[-0.2025,  0.1796,  0.2938],\n",
            "          [ 0.3048, -0.2732,  0.2842],\n",
            "          [-0.3299,  0.0659, -0.0495]]]])\n",
            "----------------------------------------------------------------------------------------------------\n",
            "conv1.bias           - size: torch.Size([3])\n",
            "tensor([-0.1888, -0.1223, -0.1941])\n",
            "----------------------------------------------------------------------------------------------------\n",
            "bn1.weight           - size: torch.Size([3])\n",
            "tensor([1., 1., 1.])\n",
            "----------------------------------------------------------------------------------------------------\n",
            "bn1.bias             - size: torch.Size([3])\n",
            "tensor([0., 0., 0.])\n",
            "----------------------------------------------------------------------------------------------------\n",
            "bn1.running_mean     - size: torch.Size([3])\n",
            "tensor([0., 0., 0.])\n",
            "----------------------------------------------------------------------------------------------------\n",
            "bn1.running_var      - size: torch.Size([3])\n",
            "tensor([1., 1., 1.])\n",
            "----------------------------------------------------------------------------------------------------\n",
            "bn1.num_batches_tracked - size: torch.Size([])\n",
            "tensor(0)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "conv2.weight         - size: torch.Size([5, 3, 3, 3])\n",
            "tensor([[[[-0.1148,  0.1610,  0.1144],\n",
            "          [-0.1461,  0.1109,  0.0340],\n",
            "          [ 0.1891, -0.1424, -0.1381]],\n",
            "\n",
            "         [[-0.1193, -0.1736, -0.0267],\n",
            "          [-0.0312, -0.0223, -0.0892],\n",
            "          [-0.1073,  0.0360, -0.0434]],\n",
            "\n",
            "         [[-0.1348, -0.1387,  0.1024],\n",
            "          [ 0.0397, -0.0577, -0.1530],\n",
            "          [-0.1001,  0.1715, -0.0153]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1722,  0.0517, -0.0629],\n",
            "          [ 0.1682,  0.0565,  0.1647],\n",
            "          [-0.0230, -0.1156, -0.1542]],\n",
            "\n",
            "         [[ 0.0370, -0.1518, -0.0013],\n",
            "          [-0.0431,  0.0341, -0.0335],\n",
            "          [-0.1219,  0.0302,  0.1259]],\n",
            "\n",
            "         [[-0.1327,  0.1287,  0.0202],\n",
            "          [-0.1142, -0.1443,  0.0142],\n",
            "          [-0.1572, -0.1501,  0.1459]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0721, -0.0297, -0.0048],\n",
            "          [-0.1838,  0.1055,  0.0106],\n",
            "          [ 0.1605, -0.0249,  0.1466]],\n",
            "\n",
            "         [[-0.0058,  0.0688, -0.1684],\n",
            "          [-0.0244, -0.0042,  0.1471],\n",
            "          [ 0.1722, -0.1729, -0.0693]],\n",
            "\n",
            "         [[-0.1367,  0.0289, -0.1668],\n",
            "          [-0.0907, -0.1705,  0.0901],\n",
            "          [-0.0084, -0.1194,  0.1117]]],\n",
            "\n",
            "\n",
            "        [[[-0.0076,  0.0846, -0.1553],\n",
            "          [ 0.1665,  0.1292,  0.0738],\n",
            "          [ 0.0451,  0.0048,  0.0185]],\n",
            "\n",
            "         [[-0.1773,  0.1831, -0.0103],\n",
            "          [ 0.1169,  0.1641, -0.0804],\n",
            "          [-0.0501, -0.0212, -0.1302]],\n",
            "\n",
            "         [[ 0.1438, -0.0782,  0.1319],\n",
            "          [-0.0802, -0.0071,  0.0556],\n",
            "          [-0.1689, -0.0469, -0.0840]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0562, -0.0257, -0.0258],\n",
            "          [ 0.1155,  0.0083, -0.1232],\n",
            "          [-0.0255,  0.1090, -0.1705]],\n",
            "\n",
            "         [[ 0.1277, -0.0081, -0.1876],\n",
            "          [ 0.1439,  0.1627, -0.0208],\n",
            "          [-0.0896, -0.1187,  0.1468]],\n",
            "\n",
            "         [[ 0.0756, -0.0290,  0.0264],\n",
            "          [-0.1586,  0.0454,  0.0562],\n",
            "          [-0.0328, -0.1194, -0.0551]]]])\n",
            "----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "handed-stomach",
        "outputId": "181e97e0-096e-4d0a-9cbc-4d9208f9a8e2"
      },
      "source": [
        "from collections import OrderedDict\n",
        "print(f\"model.state_dict() type is : {type(model.state_dict())}\")\n",
        "type(model.state_dict()) == OrderedDict"
      ],
      "id": "handed-stomach",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model.state_dict() type is : <class 'collections.OrderedDict'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "regulation-catalog"
      },
      "source": [
        "#### `named_parameters()` 을 안쓰고 `state_dict()` 을 사용하는 이유가 무언인가요? (둘이 뭐가 다른가요)\n",
        " - `named_parameters()` : returns only parameters\n",
        " - `state_dict()`: returns both parameters and buffers (e.g. BN running_mean, running_var)\n",
        "    - returns a dictionary containing a whole state of the module\n",
        " \n",
        " [Reference](https://stackoverflow.com/a/54747245)"
      ],
      "id": "regulation-catalog"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "completed-delaware",
        "outputId": "97e5b3a6-0005-4357-8afd-82b3dcb6cec0"
      },
      "source": [
        "pprint([name for (name, param) in model.named_parameters()])  # named_parameters() : returns only parameters\n",
        "print()\n",
        "pprint(list(model.state_dict().keys()))  # state_dict(): retuns both parameters and buffers"
      ],
      "id": "completed-delaware",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['conv1.weight', 'conv1.bias', 'bn1.weight', 'bn1.bias', 'conv2.weight']\n",
            "\n",
            "['conv1.weight',\n",
            " 'conv1.bias',\n",
            " 'bn1.weight',\n",
            " 'bn1.bias',\n",
            " 'bn1.running_mean',\n",
            " 'bn1.running_var',\n",
            " 'bn1.num_batches_tracked',\n",
            " 'conv2.weight']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deadly-scheme"
      },
      "source": [
        ""
      ],
      "id": "deadly-scheme",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "italic-solid"
      },
      "source": [
        "### CPU vs GPU\n",
        " - DL 모델은 다양한 프로세서(CPU, GPU, TPU) 를 사용하여 학습을 할 수 있습니다.\n",
        " - 따라서, 특정 프로세서에서 학습을 진행하고 싶은 경우 명시적으로 지정해주어야 합니다."
      ],
      "id": "italic-solid"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "documentary-bruce"
      },
      "source": [
        "#### cpu()\n",
        "Moves all model parameters and buffers to the CPU."
      ],
      "id": "documentary-bruce"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "compound-implementation",
        "outputId": "6a56d09d-22cc-4718-af19-f4138e648a36"
      },
      "source": [
        "model.cpu()\n",
        "for weight in model.parameters():\n",
        "    print(f\"model device: {weight.device}\")"
      ],
      "id": "compound-implementation",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model device: cpu\n",
            "model device: cpu\n",
            "model device: cpu\n",
            "model device: cpu\n",
            "model device: cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "directed-monster"
      },
      "source": [
        "#### cuda()\n",
        "Moves all model parameters and buffers to the GPU."
      ],
      "id": "directed-monster"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "assigned-glasgow",
        "outputId": "bcea3836-f412-4f63-a934-be0bad2146f0"
      },
      "source": [
        "model.cuda()\n",
        "for weight in model.parameters():\n",
        "    print(f\"model device: {weight.device}\")"
      ],
      "id": "assigned-glasgow",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model device: cuda:0\n",
            "model device: cuda:0\n",
            "model device: cuda:0\n",
            "model device: cuda:0\n",
            "model device: cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "humanitarian-oxide"
      },
      "source": [
        "#### to()\n",
        "Moves and/or casts the parameters and buffers"
      ],
      "id": "humanitarian-oxide"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "korean-peace",
        "outputId": "55294d8b-0e20-4233-a60d-f80cb380ab78"
      },
      "source": [
        "device_options = ['cpu', 'cuda']\n",
        "for device_option in device_options:\n",
        "    device = torch.device(device_option)\n",
        "    model.to(device)\n",
        "    \n",
        "    print(f\"Set model device to {device_option}\")\n",
        "    for weight in model.parameters():\n",
        "        print(f\"model device: {weight.device}\")\n",
        "    print()"
      ],
      "id": "korean-peace",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Set model device to cpu\n",
            "model device: cpu\n",
            "model device: cpu\n",
            "model device: cpu\n",
            "model device: cpu\n",
            "model device: cpu\n",
            "\n",
            "Set model device to cuda\n",
            "model device: cuda:0\n",
            "model device: cuda:0\n",
            "model device: cuda:0\n",
            "model device: cuda:0\n",
            "model device: cuda:0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "automotive-resolution"
      },
      "source": [
        ""
      ],
      "id": "automotive-resolution",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reserved-introduction"
      },
      "source": [
        "### forward\n",
        " - nn.Module 을 상속한 객체를 직접 호출할 때 수행하는 연산을 정의합니다.\n",
        " - `model(input)` 을 통해 모델의 예측값을 계산할 수 있습니다.\n",
        " - Defines the computation performed at every call"
      ],
      "id": "reserved-introduction"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "political-dragon",
        "outputId": "ac9cb8ff-640d-44c7-e28d-d0e72e7e1fb5"
      },
      "source": [
        "dummy_input = torch.randn(1, 1, 12, 12).to(device)\n",
        "model.to(device)\n",
        "output = model(dummy_input)  # model.forward(dummy_input)과 같다\n",
        "print(f\"model output: {output.size()}\")\n",
        "output"
      ],
      "id": "political-dragon",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model output: torch.Size([1, 5, 8, 8])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.0000, 0.0680, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0390, 0.0000, 0.2121, 0.0726, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0725, 0.0000, 0.0000, 0.0952, 0.0000, 0.0000],\n",
              "          [0.0870, 0.0000, 0.0000, 0.0000, 0.0000, 0.1270, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.1993, 0.0000, 0.0000, 0.1471, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0545, 0.0215, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0925, 0.0000, 0.0000, 0.0000]],\n",
              "\n",
              "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6296, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.5254, 0.0000, 0.4816, 0.0826, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.3775, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0105, 0.0000, 0.0000, 0.2696, 0.0000, 0.0000, 0.2483, 0.2245],\n",
              "          [0.0109, 0.2748, 0.0000, 0.0000, 0.0000, 0.0000, 0.0370, 0.1316],\n",
              "          [0.0000, 0.0781, 0.1305, 0.0000, 0.1002, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.1832, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.2209, 0.3112, 0.0000, 0.0000, 0.0000, 0.3638]],\n",
              "\n",
              "         [[0.0000, 0.0100, 0.1925, 0.1045, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2385, 0.0000, 0.1339],\n",
              "          [0.3723, 0.0000, 0.1013, 0.3390, 0.1659, 0.3321, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.1181, 0.0000, 0.0000, 0.0000, 0.1191, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2855, 0.0000, 0.3361, 0.1483],\n",
              "          [0.0430, 0.0000, 0.0000, 0.3623, 0.0000, 0.0000, 0.0000, 0.0056],\n",
              "          [0.0000, 0.0000, 0.1388, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.2020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0441, 0.0000, 0.0000]],\n",
              "\n",
              "         [[0.2263, 0.1820, 0.0000, 0.1551, 0.2266, 0.2684, 0.0000, 0.1696],\n",
              "          [0.0000, 0.1383, 0.0968, 0.1351, 0.1295, 0.0000, 0.0127, 0.0000],\n",
              "          [0.0000, 0.4200, 0.0000, 0.0000, 0.4015, 0.0000, 0.9178, 0.0000],\n",
              "          [0.1558, 0.5825, 0.0000, 0.6808, 0.2590, 0.2226, 0.2121, 0.1461],\n",
              "          [0.3494, 0.0000, 0.4411, 0.5046, 0.0000, 0.5198, 0.0000, 0.6452],\n",
              "          [0.3672, 0.0000, 0.3415, 0.0679, 0.0654, 0.3490, 0.0000, 0.7305],\n",
              "          [0.2146, 0.0000, 0.2010, 0.0209, 0.2788, 0.2414, 0.1299, 0.6389],\n",
              "          [0.2185, 0.0185, 0.3126, 0.0000, 0.3632, 0.0000, 0.5209, 0.0000]],\n",
              "\n",
              "         [[0.1142, 0.0000, 0.0000, 0.0000, 0.3630, 0.6166, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.1071, 0.0000, 0.0000, 0.3197, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.4482, 0.0018, 0.0000, 0.0630, 0.7859, 0.0128],\n",
              "          [0.0764, 0.0000, 0.0000, 0.0313, 0.2572, 0.0000, 0.4272, 0.5330],\n",
              "          [0.4880, 0.0000, 0.0000, 0.1003, 0.0855, 0.0000, 0.0581, 0.2413],\n",
              "          [0.1568, 0.2851, 0.0000, 0.0000, 0.0873, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.1688, 0.0000, 0.1646, 0.0000, 0.1115, 0.0000, 0.1221],\n",
              "          [0.0000, 0.0000, 0.4160, 0.0000, 0.0000, 0.0000, 0.2514, 0.0000]]]],\n",
              "       device='cuda:0', grad_fn=<ReluBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "royal-peninsula"
      },
      "source": [
        "#### Cautions\n",
        " - 모델과 인풋의 device 는 반드시 같아야 합니다.\n",
        " - 그렇지 않으면 (Runtime) Error 가 발생합니다."
      ],
      "id": "royal-peninsula"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utility-professor",
        "outputId": "ec861021-4aa9-413a-f471-eb203931ac8c"
      },
      "source": [
        "cpu_device = torch.device('cpu')\n",
        "gpu_device = torch.device('cuda')\n",
        "\n",
        "# device is same\n",
        "dummy_input = dummy_input.to(gpu_device)\n",
        "model.to(gpu_device)\n",
        "output = model(dummy_input)  # Fine \n",
        "print(f\"model output: {output.size()}\")"
      ],
      "id": "utility-professor",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model output: torch.Size([1, 5, 8, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "desperate-tulsa",
        "outputId": "dae67685-eaab-44b7-b7e6-57d0a5fa3999"
      },
      "source": [
        "dummy_input = dummy_input.to(cpu_device)\n",
        "model.to(gpu_device)\n",
        "\n",
        "# device is different\n",
        "# RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same\n",
        "output = model(dummy_input)  # raise Error\n",
        "print(f\"model output: {output.size()}\")"
      ],
      "id": "desperate-tulsa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _thnn_conv2d_forward",
          "traceback": [
            "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-52d7e79efd68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# device is different\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_input\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# raise Error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"model output: {output.size()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.pyenv/versions/3.6.10/envs/torch1.7/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-5f680354f5ab>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.pyenv/versions/3.6.10/envs/torch1.7/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.pyenv/versions/3.6.10/envs/torch1.7/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.pyenv/versions/3.6.10/envs/torch1.7/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    419\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 420\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _thnn_conv2d_forward"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anticipated-exclusion"
      },
      "source": [
        ""
      ],
      "id": "anticipated-exclusion",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "operational-american"
      },
      "source": [
        "### requires_grad()\n",
        " - autograd 가 해당 모델의 연산을 기록할지를 결정합니다\n",
        " - false 일 시, 수행하는 연산을 기록하지 않고 따라서 역전파가 되지 않아 학습에서 제외됩니다.\n",
        " - Change if autograd should record operations on parameters in this module."
      ],
      "id": "operational-american"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "supposed-broadcasting",
        "outputId": "0fd80a6f-6b56-429d-f318-9591e6f92bf6"
      },
      "source": [
        "# requires_grad = False\n",
        "model.requires_grad_(requires_grad=False)\n",
        "for param, weight in model.named_parameters():\n",
        "    print(f\"param {param:15} required gradient? -> {weight.requires_grad}\")"
      ],
      "id": "supposed-broadcasting",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "param conv1.weight    required gradient? -> False\n",
            "param conv1.bias      required gradient? -> False\n",
            "param bn1.weight      required gradient? -> False\n",
            "param bn1.bias        required gradient? -> False\n",
            "param conv2.weight    required gradient? -> False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "absent-strip",
        "outputId": "c3963582-fea5-4cba-80e2-7e2e8d421fea"
      },
      "source": [
        "# requires_grad = True\n",
        "model.requires_grad_(requires_grad=True)\n",
        "for param, weight in model.named_parameters():\n",
        "    print(f\"param {param:15} required gradient? -> {weight.requires_grad}\")"
      ],
      "id": "absent-strip",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "param conv1.weight    required gradient? -> True\n",
            "param conv1.bias      required gradient? -> True\n",
            "param bn1.weight      required gradient? -> True\n",
            "param bn1.bias        required gradient? -> True\n",
            "param conv2.weight    required gradient? -> True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "endless-fight"
      },
      "source": [
        ""
      ],
      "id": "endless-fight",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atmospheric-aspect"
      },
      "source": [
        "### train(), eval()\n",
        " - 모델을 training(evaluation) 모드로 전환합니다.\n",
        " - training 과 evaluation 이 다르게 작용하는 모듈들(Dropout, BatchNorm) 에 영향을 줍니다.\n",
        " - 학습 단계에서는 training 모드로, 인퍼런스 단계에서는 eval 모드로 전환해주어야 합니다.\n",
        " - [아래](https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/batchnorm.py#L111-L118)는 BatchNorm2d 의 파이토치 구현입니다. `self.training=True` 일 경우에만, `running_mean`, `running_var` 을 tracking 합니다.\n",
        " \n",
        "```\n",
        "if self.training and self.track_running_stats:\n",
        "    # TODO: if statement only here to tell the jit to skip emitting this when it is None\n",
        "    if self.num_batches_tracked is not None:\n",
        "        self.num_batches_tracked = self.num_batches_tracked + 1\n",
        "        if self.momentum is None:  # use cumulative moving average\n",
        "            exponential_average_factor = 1.0 / float(self.num_batches_tracked)\n",
        "        else:  # use exponential moving average\n",
        "            exponential_average_factor = self.momentum\n",
        "```"
      ],
      "id": "atmospheric-aspect"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nonprofit-lotus",
        "outputId": "d6f123ac-b8cf-4bfe-9935-b3f8cbf86a9f"
      },
      "source": [
        "model.train()  # set model to train mode\n",
        "print(f\"model.bn1.training: {model.bn1.training}\")"
      ],
      "id": "nonprofit-lotus",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model.bn1.training: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "worse-issue",
        "outputId": "b87994be-2350-4706-ed02-9339562dce4a"
      },
      "source": [
        "model.eval()  # set model to eval mode\n",
        "print(f\"model.bn1.training: {model.bn1.training}\")"
      ],
      "id": "worse-issue",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model.bn1.training: False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "latter-webster"
      },
      "source": [
        "### 파이토치 공식 문서에서 nn.Module 에 관한 더 많은 정보를 얻을 수 있습니다.\n",
        "https://pytorch.org/docs/stable/generated/torch.nn.Module.html\n",
        "\n",
        "궁금증이 생기면 공식 문서를 참고하는걸 강력 추천합니다."
      ],
      "id": "latter-webster"
    }
  ]
}